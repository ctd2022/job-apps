"""
CV to JSON Converter
Converts unstructured CV text to structured JSON using local Ollama LLM
Part of the job_applications workflow
"""

import requests
import json
import sys
import argparse
from pathlib import Path

def load_schema(schema_path):
    """Load the JSON schema template"""
    try:
        with open(schema_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"‚ùå Error: Schema file not found at {schema_path}")
        print("Please ensure cv_schema.json exists in the inputs folder")
        sys.exit(1)

def load_cv_text(cv_path):
    """Load CV text from file"""
    try:
        with open(cv_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        print(f"‚ùå Error: CV file not found at {cv_path}")
        sys.exit(1)

def cv_to_json(cv_text, schema, model='qwen2.5:32b'):
    """
    Convert CV text to structured JSON using Ollama
    """
    prompt = f"""You are a precise data extraction assistant specialising in UK professional CVs. Convert the following CV into JSON format that EXACTLY matches this schema structure.

REQUIRED JSON SCHEMA:
{json.dumps(schema, indent=2)}

CRITICAL INSTRUCTIONS:
- Use ISO date format (YYYY-MM-DD) for all dates
- Set is_current to true for current positions, false otherwise
- Use null for any missing information (do NOT make up data)
- Extract achievements separately from responsibilities
- Categorise skills appropriately into the provided categories
- Use UK English spelling throughout (optimisation, specialising, etc.)
- Maintain professional tone in all descriptions
- Return ONLY valid JSON, no explanations or markdown code blocks

CV CONTENT TO CONVERT:
{cv_text}

JSON OUTPUT:"""

    print("üîÑ Sending request to Ollama (this may take 2-3 minutes)...")
    
    try:
        response = requests.post('http://localhost:11434/api/generate',
                                json={
                                    'model': model,
                                    'prompt': prompt,
                                    'stream': False,
                                    'options': {
                                        'temperature': 0.1,
                                        'num_predict': 4096
                                    }
                                },
                                timeout=300)  # 5 minute timeout
        
        response.raise_for_status()
        result = response.json()
        response_text = result['response']
        
        # Clean up response if it contains markdown code blocks
        if '```json' in response_text:
            response_text = response_text.split('```json')[1].split('```')[0]
        elif '```' in response_text:
            response_text = response_text.split('```')[1].split('```')[0]
        
        return json.loads(response_text.strip())
        
    except requests.exceptions.ConnectionError:
        print("‚ùå Error: Cannot connect to Ollama. Is it running?")
        print("Try running: ollama serve")
        sys.exit(1)
    except requests.exceptions.Timeout:
        print("‚ùå Error: Request timed out. The model may be too slow.")
        print("Try using a smaller model like llama3.1:8b")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"‚ùå Error: Invalid JSON generated by the model")
        print(f"Details: {e}")
        print("\nModel's raw response:")
        print(response_text[:500])
        sys.exit(1)

def validate_json(data, schema):
    """
    Basic validation to check required fields match schema
    """
    required_top_level = list(schema.keys())
    missing = [field for field in required_top_level if field not in data]
    
    if missing:
        print(f"‚ö†Ô∏è  Warning: Missing top-level fields: {missing}")
        return False
    
    # Check experience array has required fields
    if 'experience' in data and data['experience']:
        exp_fields = ['title', 'company', 'start_date', 'is_current']
        for i, exp in enumerate(data['experience']):
            missing_exp = [f for f in exp_fields if f not in exp]
            if missing_exp:
                print(f"‚ö†Ô∏è  Warning: Experience entry {i} missing: {missing_exp}")
    
    print("‚úÖ All required top-level fields present")
    return True

def main():
    parser = argparse.ArgumentParser(
        description='Convert CV text to structured JSON using local Ollama LLM'
    )
    parser.add_argument(
        '--cv',
        type=str,
        default='inputs/my_cv.txt',
        help='Path to your CV text file (default: inputs/my_cv.txt)'
    )
    parser.add_argument(
        '--schema',
        type=str,
        default='inputs/cv_schema.json',
        help='Path to JSON schema template (default: inputs/cv_schema.json)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='inputs/my_profile.json',
        help='Output path for generated JSON (default: inputs/my_profile.json)'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='qwen2.5:32b',
        help='Ollama model to use (default: qwen2.5:32b)'
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("CV to JSON Converter")
    print("=" * 60)
    print(f"CV Input:     {args.cv}")
    print(f"Schema:       {args.schema}")
    print(f"Output:       {args.output}")
    print(f"Model:        {args.model}")
    print("=" * 60)
    print()
    
    # Load inputs
    print("üìñ Loading CV text...")
    cv_text = load_cv_text(args.cv)
    print(f"   Loaded {len(cv_text)} characters")
    
    print("üìã Loading JSON schema...")
    schema = load_schema(args.schema)
    print(f"   Schema has {len(schema)} top-level fields")
    print()
    
    # Convert
    print("ü§ñ Processing with Ollama...")
    result = cv_to_json(cv_text, schema, args.model)
    print("‚úÖ Conversion complete!")
    print()
    
    # Validate
    print("üîç Validating output...")
    validate_json(result, schema)
    print()
    
    # Save
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"üíæ Saved to: {output_path}")
    
    # Stats
    stats = []
    if 'experience' in result:
        stats.append(f"{len(result['experience'])} jobs")
    if 'education' in result:
        stats.append(f"{len(result['education'])} degrees")
    if 'projects' in result:
        stats.append(f"{len(result['projects'])} projects")
    if 'certifications' in result:
        stats.append(f"{len(result['certifications'])} certifications")
    
    if stats:
        print(f"üìä Extracted: {', '.join(stats)}")
    
    print()
    print("=" * 60)
    print("‚úÖ SUCCESS! Your CV is now in structured JSON format")
    print("=" * 60)
    print()
    print("Next steps:")
    print("1. Review the JSON file to ensure accuracy")
    print("2. Update any fields that need correction")
    print("3. Use this as your single source of truth")
    print("4. Update job_application_workflow.py to use the JSON")

if __name__ == "__main__":
    main()